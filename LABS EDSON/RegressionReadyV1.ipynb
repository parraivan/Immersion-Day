{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import calendar\n",
    "import boto3\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "s3 = boto3.resource('s3')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download, uncompress and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://edzon.io/datasets/bike_share_dataset.zip -O bike_share_dataset.zip\n",
    "!unzip -o bike_share_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_df = pd.read_csv('bike_share_data.csv')\n",
    "weathers_df = pd.read_csv('weathers.csv').set_index('id')\n",
    "seasons_df = pd.read_csv('seasons.csv').set_index('id')\n",
    "weekdays_df = pd.read_csv('weekdays.csv').set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset columns\n",
    "* **season:** Spring, Summer, Fall or Winter\n",
    "* **holiday:** 1 - Yes, 0 - No\n",
    "* **weekday:** Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday\n",
    "* **workingday:** 1 - Yes, 0 - No\n",
    "* **weather:** clear - Clear, Few clouds, Partly cloudy, Partly cloudy<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;misty_cloudy - Misty and Cloudy, Misty with Broken clouds, Misty with Few clouds, Misty<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ligth_rain_snow - Light Snow, Light Rain and Thunderstorm, Light Rain and Scatter clouds<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;heavy_rain_snow - Heavy Rain and Ice Pallets, Thunderstorm, Snow and Fog\n",
    "* **temp:** Normalized temperature in Celsius\n",
    "* **atemp:** Normalized feeling temperature in Celsius\n",
    "* **humidity:** Normalized humidity\n",
    "* **count:** Count of total rental bikes aggregated in one hour\n",
    "* **datetime:** The hour and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since fields: season, weekday and weather are categorical, we have to change to one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, categories_df, column_name):\n",
    "    categories = pd.api.types.CategoricalDtype(categories=categories_df.values.flatten())\n",
    "    df[column_name]=df[column_name].astype(categories)\n",
    "    df = pd.concat([df,pd.get_dummies(df[column_name],prefix=column_name)],axis=1)\n",
    "    df.drop([column_name],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_df = one_hot_encoding(bike_share_df,weathers_df,'weather')\n",
    "bike_share_df = one_hot_encoding(bike_share_df,seasons_df,'season')\n",
    "bike_share_df = one_hot_encoding(bike_share_df,weekdays_df,'weekday')\n",
    "bike_share_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_date(df, column_name):\n",
    "    result = df\n",
    "    result[column_name] = pd.to_datetime(df[column_name],infer_datetime_format=True)\n",
    "    result['month']=result[column_name].dt.strftime('%b')\n",
    "    result['hour']=result[column_name].dt.hour\n",
    "    result.drop([column_name],axis=1, inplace=True)\n",
    "    \n",
    "    bike_share_df.loc[bike_share_df['hour'] < 12, 'time_of_day'] = 'Morning'\n",
    "    bike_share_df.loc[(bike_share_df['hour'] >= 12) & (bike_share_df['hour'] < 17), 'time_of_day'] = 'Afternoon'\n",
    "    bike_share_df.loc[bike_share_df['hour'] >= 17, 'time_of_day'] = 'Evening'\n",
    "    result.drop(['hour'],axis=1, inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_df = split_date(bike_share_df,'datetime')\n",
    "bike_share_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_month(df, column_name):\n",
    "    months = []\n",
    "    for i in range(1,13):\n",
    "        months.append((i, calendar.month_name[i][0:3]))\n",
    "    months = pd.DataFrame(months, columns=['id','month'])\n",
    "    months = months.set_index('id')\n",
    "    return one_hot_encoding(df,months, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_time(df, column_name):\n",
    "    momentum = pd.DataFrame(\"Morning,Afternoon,Evening\".split(','))\n",
    "    return one_hot_encoding(df, momentum, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_df = encode_month(bike_share_df, 'month')\n",
    "bike_share_df = encode_time(bike_share_df, 'time_of_day')\n",
    "bike_share_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move target to first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_target(df,target):\n",
    "    target_column = df[target]\n",
    "    df.drop([target], axis=1, inplace = True)\n",
    "    df.insert(0,target,target_column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_df = move_target(bike_share_df,'count')\n",
    "bike_share_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(df, train_size):\n",
    "    return np.split(df.sample(frac=1), [int(train_size*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_val_split(bike_share_df, .7)\n",
    "\n",
    "train_file='train_data.csv'\n",
    "val_file='val_data.csv'\n",
    "\n",
    "train_df.to_csv(train_file, index=False, header=False)\n",
    "val_df.to_csv(val_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(bucket, prefix, file):    \n",
    "    data = open(file, \"rb\")\n",
    "    key = '{}/{}'.format(prefix, file)\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data, ContentType='text/csv')\n",
    "    path = 's3://{}/{}'.format(bucket, key)\n",
    "    print(path)\n",
    "    return path\n",
    "\n",
    "def create_data_channels(train_file, val_file):\n",
    "    s3_train_data = upload_to_s3(bucket,'{}/train'.format(prefix),train_file)\n",
    "    s3_val_data = upload_to_s3(bucket,'{}/val'.format(prefix),val_file)\n",
    "    \n",
    "    train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                                        content_type='text/csv', s3_data_type='S3Prefix')\n",
    "    val_data = sagemaker.session.s3_input(s3_val_data, distribution='FullyReplicated', \n",
    "                                        content_type='text/csv', s3_data_type='S3Prefix')\n",
    "        \n",
    "    return {'train': train_data, 'validation': val_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'edzon-test'\n",
    "prefix = 'sagemaker/Lab-linear-learner'\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = create_data_channels(train_file, val_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.c5.xlarge', \n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sess)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim=len(train_df.columns)-1,\n",
    "                           predictor_type='regressor',\n",
    "                           early_stopping_patience=50,\n",
    "                           early_stopping_tolerance=0.001,\n",
    "                           epochs=120,                           \n",
    "                           learning_rate='auto',\n",
    "                           loss='squared_loss',\n",
    "                           optimizer='sgd',\n",
    "                           mini_batch_size=100)\n",
    "\n",
    "linear.fit(data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realtime inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = csv_serializer\n",
    "linear_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = linear_predictor.predict(train_df.iloc[20].drop(['count']))\n",
    "print(\"prediction: {}\".format(result['predictions'][0]['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_prediction(df, predictor):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    target_column = df.columns[0]\n",
    "    for index, row in df.iterrows():\n",
    "        labels.append(row[target_column])\n",
    "        predictions.append(predictor.predict(row.drop(target_column))['predictions'][0]['score'])\n",
    "    \n",
    "    %matplotlib inline\n",
    "\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    matplotlib.rcParams['figure.dpi'] = 100\n",
    "\n",
    "    plt.plot(np.array(labels),label='actual')\n",
    "    plt.plot(np.array(predictions),label='prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_actual_vs_prediction(val_df.sample(n=200), linear_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting model parameters\n",
    "#### Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '{}/output/{}/output/model.tar.gz'.format(prefix, linear.latest_training_job.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mxnet as mx\n",
    "\n",
    "s3.Bucket(bucket).download_file(model_file, os.path.basename(model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -zxvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear learner model is itself a zip file, containing a mxnet model and other metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip model_algo-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the mxnet module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mx.module.Module.load(\"mx-mod\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod._arg_params['fc0_weight'].asnumpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod._arg_params['fc0_bias'].asnumpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', '0.90-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.c5.xlarge', \n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sess)\n",
    "\n",
    "xgboost.set_hyperparameters(max_depth=6,\n",
    "                            eta=0.3,\n",
    "                            gamma=0,\n",
    "                            min_child_weight=1,\n",
    "                            subsample=1,\n",
    "                            silent=0,\n",
    "                            objective=\"reg:linear\",\n",
    "                            num_round=120)\n",
    "\n",
    "xgboost.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_predictor = xgboost.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realtime inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_predictor.content_type = 'text/csv'\n",
    "xgboost_predictor.serializer = csv_serializer\n",
    "xgboost_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = xgboost_predictor.predict(train_df.iloc[20].drop(['count']))\n",
    "print(\"prediction: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_plot_actual_vs_prediction(df, predictor):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    target_column = df.columns[0]\n",
    "    for index, row in df.iterrows():\n",
    "        labels.append(row[target_column])    \n",
    "        predictions.append(predictor.predict(row.drop(target_column)))\n",
    "    \n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    matplotlib.rcParams['figure.dpi'] = 100\n",
    "\n",
    "    plt.plot(np.array(labels),label='actual')\n",
    "    plt.plot(np.array(predictions),label='prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = val_df.sample(n=200)\n",
    "xgboost_plot_actual_vs_prediction(sample, xgboost_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VS linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_actual_vs_prediction(sample, linear_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
